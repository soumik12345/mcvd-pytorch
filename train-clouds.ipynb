{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09062df-6ed5-4642-a3b2-2eb2b78bfbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e2676e-c373-407a-a6b1-ddcf0406e060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "import numpy as np\n",
    "import ml_collections\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import (\n",
    "    get_dataset, data_transform, inverse_data_transform\n",
    ")\n",
    "\n",
    "from models import eval_models\n",
    "from models.ema import EMAHelper\n",
    "from models.unet import UNet_SMLD, UNet_DDPM\n",
    "from models.fvd.fvd import (\n",
    "    get_fvd_feats, frechet_distance, load_i3d_pretrained\n",
    ")\n",
    "from models import (\n",
    "    ddpm_sampler,\n",
    "    ddim_sampler,\n",
    "    FPNDM_sampler,\n",
    "    anneal_Langevin_dynamics,\n",
    "    anneal_Langevin_dynamics_consistent,\n",
    "    anneal_Langevin_dynamics_inpainting,\n",
    "    anneal_Langevin_dynamics_interpolation\n",
    ")\n",
    "from models.better.ncsnpp_more import UNetMore_DDPM\n",
    "\n",
    "from losses import get_optimizer, warmup_lr\n",
    "from losses.dsm import anneal_dsm_score_estimation\n",
    "\n",
    "from load_model_from_ckpt import init_samples as initialize_samples\n",
    "from runners.ncsn_runner import conditioning_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b346b63e-b41e-475d-a467-9f2aa80df9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_configs() -> ml_collections.ConfigDict:\n",
    "    config = ml_collections.ConfigDict()\n",
    "\n",
    "    config.channels = 1\n",
    "    config.dataset = 'StochasticMovingMNIST'\n",
    "    config.gaussian_dequantization = False\n",
    "    config.image_size = 64\n",
    "    config.logit_transform = False\n",
    "    config.num_digits = 2\n",
    "    config.num_frames = 5\n",
    "    config.num_frames_cond = 5\n",
    "    config.num_frames_future = 0\n",
    "    config.num_workers = 0\n",
    "    config.prob_mask_cond = 0.0\n",
    "    config.prob_mask_future = 0.0\n",
    "    config.prob_mask_sync = False\n",
    "    config.random_flip = True\n",
    "    config.rescaled = True\n",
    "    config.step_length = 0.1\n",
    "    config.uniform_dequantization = False\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def get_fast_fid_configs() -> ml_collections.ConfigDict:\n",
    "    config = ml_collections.ConfigDict()\n",
    "\n",
    "    config.batch_size = 1000\n",
    "    config.begin_ckpt = 5000\n",
    "    config.end_ckpt = 300000\n",
    "    config.ensemble = False\n",
    "    config.freq = 5000\n",
    "    config.n_steps_each = 0\n",
    "    config.num_samples = 1000\n",
    "    config.pr_nn_k = 3\n",
    "    config.step_lr = 0.0\n",
    "    config.verbose = False\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def get_model_configs() -> ml_collections.ConfigDict:\n",
    "    config = ml_collections.ConfigDict()\n",
    "\n",
    "    config.arch = 'unetmore'\n",
    "    config.attn_resolutions = [8, 16, 32]\n",
    "    config.ch_mult = [1, 2, 3, 4]\n",
    "    config.cond_emb = False\n",
    "    config.conditional = True\n",
    "    config.depth = 'deep'\n",
    "    config.dropout = 0.1\n",
    "    config.ema = True\n",
    "    config.ema_rate = 0.999\n",
    "    config.gamma = False\n",
    "    config.n_head_channels = 64\n",
    "    config.ngf = 64\n",
    "    config.noise_in_cond = False\n",
    "    config.nonlinearity = 'swish'\n",
    "    config.normalization = 'InstanceNorm++'\n",
    "    config.num_classes = 1000\n",
    "    config.num_res_blocks = 2\n",
    "    config.output_all_frames = False\n",
    "    config.sigma_begin = 0.02\n",
    "    config.sigma_dist = 'linear'\n",
    "    config.sigma_end = 0.0001\n",
    "    config.spade = False\n",
    "    config.spade_dim = 128\n",
    "    config.spec_norm = False\n",
    "    config.time_conditional = True\n",
    "    config.type = 'v1'\n",
    "    config.scheduler = 'DDPM'\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def get_optim_configs() -> ml_collections.ConfigDict:\n",
    "    config = ml_collections.ConfigDict()\n",
    "\n",
    "    config.amsgrad = False\n",
    "    config.beta1 = 0.9\n",
    "    config.eps = 1e-08\n",
    "    config.grad_clip = 1.0\n",
    "    config.lr = 0.0002\n",
    "    config.optimizer = 'Adam'\n",
    "    config.warmup = 1000\n",
    "    config.weight_decay = 0.0\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def get_sampling_configs() -> ml_collections.ConfigDict:\n",
    "    config = ml_collections.ConfigDict()\n",
    "\n",
    "    config.batch_size = 100\n",
    "    config.ckpt_id = 0\n",
    "    config.clip_before = True\n",
    "    config.consistent = True\n",
    "    config.data_init = False\n",
    "    config.denoise = True\n",
    "    config.fid = False\n",
    "    config.final_only = True\n",
    "    config.fvd = True\n",
    "    config.init_prev_t = -1.0\n",
    "    config.inpainting = False\n",
    "    config.interpolation = False\n",
    "    config.max_data_iter = 100000\n",
    "    config.n_interpolations = 15\n",
    "    config.n_steps_each = 0\n",
    "    config.num_frames_pred = 20\n",
    "    config.num_samples4fid = 10000\n",
    "    config.num_samples4fvd = 10000\n",
    "    config.one_frame_at_a_time = False\n",
    "    config.preds_per_test = 1\n",
    "    config.ssim = True\n",
    "    config.step_lr = 0.0\n",
    "    config.subsample = 1000\n",
    "    config.train = False\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def get_test_configs() -> ml_collections.ConfigDict:\n",
    "    config = ml_collections.ConfigDict()\n",
    "\n",
    "    config.batch_size = 100\n",
    "    config.begin_ckpt = 5000\n",
    "    config.end_ckpt = 300000\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def get_training_configs() -> ml_collections.ConfigDict:\n",
    "    config = ml_collections.ConfigDict()\n",
    "\n",
    "    config.L1 = False\n",
    "    config.batch_size = 64\n",
    "    config.checkpoint_freq = 100\n",
    "    config.log_all_sigmas = False\n",
    "    config.log_freq = 50\n",
    "    config.n_epochs = 10\n",
    "    config.n_iters = 3000001\n",
    "    config.sample_freq = 50000\n",
    "    config.snapshot_freq = 1000\n",
    "    config.snapshot_sampling = True\n",
    "    config.val_freq = 100\n",
    "    config.checkpoint_dir = \"smmnist_cat\"\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def get_config() -> ml_collections.ConfigDict:\n",
    "    config = ml_collections.ConfigDict()\n",
    "    \n",
    "    config.data = get_data_configs()\n",
    "    config.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    config.fast_fid = get_fast_fid_configs()\n",
    "    config.model = get_model_configs()\n",
    "    config.optim = get_optim_configs()\n",
    "    config.sampling = get_sampling_configs()\n",
    "    config.test = get_test_configs()\n",
    "    config.training = get_training_configs()\n",
    "    config.start_at = 0\n",
    "    \n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaafa02-bb0c-45dc-90bc-2007ad619e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls(path): \n",
    "    return sorted(list(path.iterdir()))\n",
    "\n",
    "\n",
    "def count_trainable_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae26a4d7-7535-450b-be1b-adf155cae634",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config()\n",
    "config_dict = config.to_dict()\n",
    "config_dict.pop(\"device\", None)\n",
    "\n",
    "wandb.init(\n",
    "    project=\"masked-conditional-video-diffusion\",\n",
    "    entity=\"wandb\",\n",
    "    job_type=\"test\",\n",
    "    config=config_dict\n",
    ")\n",
    "\n",
    "wandb_config = wandb.config\n",
    "\n",
    "artifact = wandb.use_artifact('capecape/gtc/np_dataset:v0', type='dataset')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac577647-f9a9-407b-87b3-e348d42f3672",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudDataset:\n",
    "    \n",
    "    def __init__(self, files, num_frames=4, scale=True, size=64):\n",
    "        self.num_frames = num_frames\n",
    "        self.size = size\n",
    "        self.tfms = T.Compose([\n",
    "            T.Resize((size, int(size * 1.7))),\n",
    "            T.CenterCrop(size)\n",
    "        ])\n",
    "        data = []\n",
    "        for file in tqdm(files):\n",
    "            one_day = np.load(file)\n",
    "            one_day = 0.5 - self._scale(one_day) if scale else one_day\n",
    "            wds = np.lib.stride_tricks.sliding_window_view(\n",
    "                one_day.squeeze(), \n",
    "                num_frames, \n",
    "                axis=0\n",
    "            ).transpose((0, 3, 1, 2))\n",
    "            data.append(wds)\n",
    "        self.data = np.concatenate(data, axis=0)\n",
    "            \n",
    "    @staticmethod\n",
    "    def _scale(arr):\n",
    "        \"Scales values of array in [0,1]\"\n",
    "        m, M = arr.min(), arr.max()\n",
    "        return (arr - m) / (M - m)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.tfms(torch.from_numpy(self.data[idx]))\n",
    "        data = torch.unsqueeze(data, dim=-3)\n",
    "        return data, data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def save(self, fname=\"cloud_frames.npy\"):\n",
    "        np.save(fname, self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a3810a-8f0e-4570-a346-3de52a006ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(images, figure_size=(12, 12)):\n",
    "    fig = plt.figure(figsize=figure_size)\n",
    "    for i in range(len(images)):\n",
    "        fig.add_subplot(1, len(images), i + 1)\n",
    "        _ = plt.imshow(images[i])\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569b7998-5190-40f5-ae24-fb21a7dcd1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ls(Path(artifact_dir))\n",
    "train_ds = CloudDataset(\n",
    "    files,\n",
    "    num_frames=config.data.num_frames + config.data.num_frames_cond,\n",
    "    size=config.data.image_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef05ba9-1309-46ab-a2b3-1d803fc2bfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results([\n",
    "    torch.squeeze(train_ds[0][0]).numpy()[i]\n",
    "    for i in range(config.data.num_frames + config.data.num_frames_cond)\n",
    "])\n",
    "plot_results([\n",
    "    torch.squeeze(train_ds[0][1]).numpy()[i]\n",
    "    for i in range(config.data.num_frames + config.data.num_frames_cond)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b15b41-6106-4a60-9428-b8343ae083ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=config.training.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=config.data.num_workers\n",
    ")\n",
    "x, y = next(iter(train_loader))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269de9cf-2e2d-490e-b681-52fe31705258",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorenet = UNetMore_DDPM(config).to(config.device)\n",
    "scorenet = torch.nn.DataParallel(scorenet)\n",
    "optimizer = get_optimizer(config, scorenet.parameters())\n",
    "\n",
    "wandb.log({\n",
    "    \"Parameters\": count_parameters(scorenet),\n",
    "    \"Trainable Parameters\": count_trainable_parameters(scorenet)\n",
    "}, commit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49a2d6c-9ce2-4db3-854f-a0b9c3325435",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    num_devices = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs : {num_devices}\")\n",
    "    for i in range(num_devices):\n",
    "        print(torch.cuda.get_device_properties(i))\n",
    "else:\n",
    "    print(f\"Running on CPU!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc7f236-80b8-48c5-8e9c-99f5839c053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.model.ema:\n",
    "    ema_helper = EMAHelper(mu=config.model.ema_rate)\n",
    "    ema_helper.register(scorenet)\n",
    "\n",
    "net = scorenet.module if hasattr(scorenet, 'module') else scorenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f69f972-f3be-4cdf-afe1-a80c63dfe77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional = config.data.num_frames_cond > 0\n",
    "cond, test_cond = None, None\n",
    "future = getattr(config.data, \"num_frames_future\", 0)\n",
    "n_init_samples = min(36, config.training.batch_size)\n",
    "init_samples_shape = (\n",
    "    n_init_samples,\n",
    "    config.data.channels * config.data.num_frames,\n",
    "    config.data.image_size,\n",
    "    config.data.image_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aa7625-d23d-41c6-8c66-e9fbdd4b1dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.model.scheduler == \"SMLD\":\n",
    "    init_samples = data_transform(\n",
    "        config,\n",
    "        torch.rand(init_samples_shape, device=config.device)\n",
    "    )\n",
    "elif config.model.scheduler in [\"DDPM\", \"DDIM\", \"FPNDM\"]:\n",
    "    if getattr(config.model, 'gamma', False):\n",
    "        used_k, used_theta = net.k_cum[0], net.theta_t[0]\n",
    "        z = torch.distributions.gamma(\n",
    "            torch.full(init_samples_shape, used_k),\n",
    "            torch.full(init_samples_shape, 1 / used_theta)\n",
    "        ).sample().to(config.device)\n",
    "        init_samples = z - used_k * used_theta\n",
    "    else:\n",
    "        init_samples = torch.randn(init_samples_shape, device=config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412dae88-e81c-40c6-8515-b580f017f22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.model.scheduler == \"SMLD\":\n",
    "    consistent = getattr(config.sampling, 'consistent', False)\n",
    "    sampler = anneal_Langevin_dynamics_consistent if consistent else anneal_Langevin_dynamics\n",
    "elif config.model.scheduler == \"DDPM\":\n",
    "    sampler = partial(ddpm_sampler, config=config)\n",
    "elif config.model.scheduler == \"DDIM\":\n",
    "    sampler = partial(ddim_sampler, config=config)\n",
    "elif config.model.scheduler == \"FPNDM\":\n",
    "    sampler = partial(FPNDM_sampler, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56fff6b-b0cd-4775-b6bc-34dc5801f47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x, y, step):\n",
    "    optimizer.zero_grad()\n",
    "    lr = warmup_lr(\n",
    "        optimizer, step,\n",
    "        getattr(config.optim, 'warmup', 0),\n",
    "        config.optim.lr\n",
    "    )\n",
    "    scorenet.train()\n",
    "    \n",
    "    x = x.to(config.device)\n",
    "    x = data_transform(config, x)\n",
    "    x, cond, cond_mask = conditioning_fn(\n",
    "        config, x, num_frames_pred=config.data.num_frames,\n",
    "        prob_mask_cond=getattr(config.data, 'prob_mask_cond', 0.0),\n",
    "        prob_mask_future=getattr(config.data, 'prob_mask_future', 0.0),\n",
    "        conditional=conditional\n",
    "    )\n",
    "    \n",
    "    loss = anneal_dsm_score_estimation(\n",
    "        scorenet, x, labels=None, cond=cond, cond_mask=cond_mask,\n",
    "        loss_type=getattr(config.training, 'loss_type', 'a'),\n",
    "        gamma=getattr(config.model, 'gamma', False),\n",
    "        L1=getattr(config.training, 'L1', False), hook=None,\n",
    "        all_frames=getattr(config.model, 'output_all_frames', False)\n",
    "    )\n",
    "    loss.backward()\n",
    "    \n",
    "    grad_norm = torch.nn.utils.clip_grad_norm_(\n",
    "        scorenet.parameters(), getattr(config.optim, 'grad_clip', np.inf)\n",
    "    )\n",
    "    optimizer.step()\n",
    "    \n",
    "    if config.model.ema:\n",
    "        ema_helper.update(scorenet)\n",
    "    \n",
    "    return loss.item(), grad_norm.item(), lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a321abe9-d71f-4d88-99e8-351d51a8d686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_step(epoch):\n",
    "    test_scorenet = ema_helper.ema_copy(scorenet) if config.model.ema else scorenet\n",
    "    test_scorenet.eval()\n",
    "    x, y = next(iter(test_loader))\n",
    "    x = x.to(config.device)\n",
    "    x = data_transform(config, x)\n",
    "    x, test_cond, test_cond_mask = conditioning_fn(\n",
    "        config, x, num_frames_pred=config.data.num_frames,\n",
    "        prob_mask_cond=getattr(config.data, 'prob_mask_cond', 0.0),\n",
    "        prob_mask_future=getattr(config.data, 'prob_mask_future', 0.0),\n",
    "        conditional=conditional\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        test_dsm_loss = anneal_dsm_score_estimation(\n",
    "            test_scorenet, x, labels=None,\n",
    "            cond=test_cond, cond_mask=test_cond_mask,\n",
    "            loss_type=getattr(config.training, 'loss_type', 'a'),\n",
    "            gamma=getattr(config.model, 'gamma', False),\n",
    "            L1=getattr(config.training, 'L1', False), hook=None,\n",
    "            all_frames=getattr(config.model, 'output_all_frames', False)\n",
    "        )\n",
    "        if wandb.run is not None:\n",
    "            wandb.log({\n",
    "                \"validation/epoch\": epoch,\n",
    "                \"validation/loss\": test_dsm_loss.item(),\n",
    "            }, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac3f585-99b5-4d35-b9b6-4451236230bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(scorenet, epoch):\n",
    "    states = [scorenet.state_dict(), optimizer.state_dict(), epoch, step]\n",
    "    if config.model.ema:\n",
    "        states.append(ema_helper.state_dict())\n",
    "    checkpoint_path = os.path.join(config.training.checkpoint_dir, 'checkpoint.pt')\n",
    "    torch.save(states, checkpoint_path)\n",
    "    if wandb.run is not None:\n",
    "        artifact = wandb.Artifact(\n",
    "            f'checkpoint-{wandb.run.name}-{wandb.run.id}', type='model'\n",
    "        )\n",
    "        artifact.add_file(checkpoint_path)\n",
    "        wandb.log_artifact(artifact, aliases=[\"latest\", f\"epoch-{epoch}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b418488-6c06-40ce-9fb1-79ccecdd24a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "\n",
    "for epoch in range(1, config.training.n_epochs + 1):\n",
    "    train_pbar = tqdm(\n",
    "        enumerate(train_loader),\n",
    "        total=len(train_loader),\n",
    "        desc=f\"Training Epoch {epoch}\"\n",
    "    )\n",
    "    for batch, (x, y) in train_pbar:\n",
    "        loss, grad_norm, lr = train_step(x, y, step)\n",
    "        if wandb.run is not None:\n",
    "            wandb.log({\n",
    "                \"train/step\": step,\n",
    "                \"lr\": lr,\n",
    "                \"grad_norm\": grad_norm,\n",
    "                \"train/loss\": loss,\n",
    "            }, step=step)\n",
    "            step += 1\n",
    "    save_model(scorenet, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6ac50e-dc33-4cbb-8fca-94078ebe8213",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-12.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-12:m102"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
